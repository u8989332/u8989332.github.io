<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="安裝 Hadoop 2.7.1 Cluster 在 VirtualBox 0.前言　　小弟開始在軟體業工作，是做Big Data Hadoop系統開發，開始會寫些對Hadoop系統或工作上學到的技術的文章，希望能幫助到一起學習的同伴。 　　首先本篇的內容是使用Oracle Virtual Box 安裝 Hadoop cluster，以下會依序介紹該如何安裝server、設定網路、安裝Hadoop、">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop 2.7.1 Cluster 安裝在 VirtualBox">
<meta property="og:url" content="http://example.com/2015/09/06/hadoop-2-7-1-cluster/index.html">
<meta property="og:site_name" content="GeekCodeParadise">
<meta property="og:description" content="安裝 Hadoop 2.7.1 Cluster 在 VirtualBox 0.前言　　小弟開始在軟體業工作，是做Big Data Hadoop系統開發，開始會寫些對Hadoop系統或工作上學到的技術的文章，希望能幫助到一起學習的同伴。 　　首先本篇的內容是使用Oracle Virtual Box 安裝 Hadoop cluster，以下會依序介紹該如何安裝server、設定網路、安裝Hadoop、">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://geekcodeparadise.com/wp-content/uploads/2015/09/hadoop-administration-pdf-21-638.jpg">
<meta property="og:image" content="http://geekcodeparadise.com/wp-content/uploads/2015/09/25E425BB258B25E9259D25A225E5258D25A11.png">
<meta property="og:image" content="http://geekcodeparadise.com/wp-content/uploads/2015/09/25E425BB258B25E9259D25A225E5258D25A12.png">
<meta property="og:image" content="http://geekcodeparadise.com/wp-content/uploads/2015/09/25E825A825AD25E525AE259Ahostname.png">
<meta property="og:image" content="http://geekcodeparadise.com/wp-content/uploads/2015/09/25E525AE258925E825A3259DServer25E525A5259725E425BB25B6.png">
<meta property="og:image" content="http://geekcodeparadise.com/wp-content/uploads/2015/09/25E725B625B225E825B725AF25E52596259C25E525A525BD25E825A825AD25E525AE259A1.png">
<meta property="og:image" content="http://geekcodeparadise.com/wp-content/uploads/2015/09/25E725B625B225E825B725AF25E52596259C25E525A525BD25E825A825AD25E525AE259A2.png">
<meta property="og:image" content="http://geekcodeparadise.com/wp-content/uploads/2015/09/25E725B625B225E825B725AF25E52596259C25E525A525BD25E825A825AD25E525AE259A3.png">
<meta property="og:image" content="http://geekcodeparadise.com/wp-content/uploads/2015/09/IPADDRSHOW.png">
<meta property="og:image" content="http://geekcodeparadise.com/wp-content/uploads/2015/09/SSH25E8258725AA25E525B725B1.png">
<meta property="og:image" content="http://geekcodeparadise.com/wp-content/uploads/2015/09/25E425B8258BHADOOP25E6258C258725E425BB25A4.png">
<meta property="og:image" content="http://geekcodeparadise.com/wp-content/uploads/2015/09/clone.png">
<meta property="og:image" content="http://geekcodeparadise.com/wp-content/uploads/2015/09/START-ALL.png">
<meta property="og:image" content="http://geekcodeparadise.com/wp-content/uploads/2015/09/JPS-MASTER.png">
<meta property="og:image" content="http://geekcodeparadise.com/wp-content/uploads/2015/09/JPS-SLAVE.png">
<meta property="og:image" content="http://geekcodeparadise.com/wp-content/uploads/2015/09/4055767_38d37c85866b5a95bcf9da64b82daf72.gif">
<meta property="og:image" content="http://geekcodeparadise.com/wp-content/uploads/2015/09/50070portpage.png">
<meta property="og:image" content="http://geekcodeparadise.com/wp-content/uploads/2015/09/8088portpage.png">
<meta property="og:image" content="http://geekcodeparadise.com/wp-content/uploads/2015/09/STOP-ALL.png">
<meta property="article:published_time" content="2015-09-06T15:05:00.000Z">
<meta property="article:modified_time" content="2023-11-19T07:47:25.442Z">
<meta property="article:author" content="LiJyu Gao">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://geekcodeparadise.com/wp-content/uploads/2015/09/hadoop-administration-pdf-21-638.jpg">

<link rel="canonical" href="http://example.com/2015/09/06/hadoop-2-7-1-cluster/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Hadoop 2.7.1 Cluster 安裝在 VirtualBox | GeekCodeParadise</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">GeekCodeParadise</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2015/09/06/hadoop-2-7-1-cluster/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LiJyu Gao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GeekCodeParadise">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Hadoop 2.7.1 Cluster 安裝在 VirtualBox
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2015-09-06 23:05:00" itemprop="dateCreated datePublished" datetime="2015-09-06T23:05:00+08:00">2015-09-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-11-19 15:47:25" itemprop="dateModified" datetime="2023-11-19T15:47:25+08:00">2023-11-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Hadoop/" itemprop="url" rel="index"><span itemprop="name">Hadoop</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Big-Data/" itemprop="url" rel="index"><span itemprop="name">Big Data</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>安裝 Hadoop 2.7.1 Cluster 在 VirtualBox</p>
<h4 id="0-前言"><a href="#0-前言" class="headerlink" title="0.前言"></a>0.前言</h4><p>　　小弟開始在軟體業工作，是做Big Data Hadoop系統開發，開始會寫些對Hadoop系統或工作上學到的技術的文章，希望能幫助到一起學習的同伴。</p>
<p>　　首先本篇的內容是使用Oracle Virtual Box 安裝 Hadoop cluster，以下會依序介紹該如何安裝server、設定網路、安裝Hadoop、參考文獻等。<br>　　先非常簡單講解Hadoop的理論，如下圖所示</p>
<p><a target="_blank" rel="noopener" href="http://geekcodeparadise.com/wp-content/uploads/2015/09/hadoop-administration-pdf-21-638-1.jpg"><img src="http://geekcodeparadise.com/wp-content/uploads/2015/09/hadoop-administration-pdf-21-638.jpg" alt="Hadoop的理論"></a></p>
<p>來自於Edureka!：Hadoop Administration pdf</p>
<p> 　　Hadoop主要有HDFS(Hadoop Distributed File System)與MapReduce 2項核心系統。HDFS是分散式的檔案系統，任何要用Hadoop做資料運算，都得從HDFS存取。細分有namenode、secondarynamnenode及datanode，主節點(Master)的namenode管理datanode metadata(位置、大小等屬性)，secondarynamnenode是輔助namenode，分擔namenode的運作，而從節點(Slave)datanode則是存取資料的節點;MapReduce則是分散式的計算技術，主節點(Master)透過Job tracker會呼叫每個從節點的Task tracker做計算，從節點(Slave)Task tracker使用Map(Divide)函式將資料切割計算，之後各Task tracker使用Reduce(Conquer)函式結合計算結果並傳回到主節點。<br>　　本篇虛擬cluster共設置3台節點，第1台hadoop01為主節點(Master)，第2、3台hadoop02與hadoop03為從節點(Slaves)</p>
<h4 id="1-準備軟體工具與配備需求"><a href="#1-準備軟體工具與配備需求" class="headerlink" title="1.準備軟體工具與配備需求"></a>1.準備軟體工具與配備需求</h4><p>安裝Hadoop需要的軟體工具清單：</p>
<ul>
<li><p>(1) Oracle Virtual Box ，本篇使用5.0.4版，用此虛擬機來安裝server ， <a target="_blank" rel="noopener" href="https://www.virtualbox.org/wiki/Downloads">官方連結點我下載</a></p>
</li>
<li><p>(2) Linux 映像檔 ，本篇使用 Ubuntu 14.04.3 LTS 64位元server版本做為虛擬機的server，<a target="_blank" rel="noopener" href="http://www.ubuntu.com/download/server">官方連結點我下載</a></p>
</li>
<li><p>(3) Putty ，很常見的SSH&#x2F;Telnet 終端機連線工具，方便連server測試使用，<a target="_blank" rel="noopener" href="http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html">官方連結點我下載</a></p>
</li>
<li><p>(4) Notepad++ ，免費的文字編輯器，擁有FTP連線編輯文字檔的功能，不用在command mode 環境下用vim&#x2F;vi&#x2F;nano辛苦的編輯文字檔！另一篇文章會介紹如何使用FTP功能。<a target="_blank" rel="noopener" href="https://notepad-plus-plus.org/">官方連結點我下載</a></p>
</li>
<li><p>(5) FileZilla FTP client，可透過FTP上傳／下載server的資料。<a target="_blank" rel="noopener" href="https://filezilla-project.org/download.php?type=client">官方連結點我下載</a>  </p>
</li>
<li><p>(6) MobaXterm ，很多功能的SSH&#x2F;Telnet 終端機連線工具，其功能包含FTP、自動連結putty已設置的站台，畫面也好看，現在改用這個就能完成很多工作了。有免費版，<a target="_blank" rel="noopener" href="http://mobaxterm.mobatek.net/download.html">官方連結點我下載</a></p>
</li>
<li><p>(7) 瀏覽器，能打開網頁看Hadoop運行狀況（遭打）</p>
</li>
</ul>
<p>本篇主機含16GB的記憶體、2TB的硬碟，以下的虛擬機系統配置依照個人需求而調整。</p>
<h4 id="2-安裝Linux-Ubuntu-server虛擬機"><a href="#2-安裝Linux-Ubuntu-server虛擬機" class="headerlink" title="2.安裝Linux Ubuntu server虛擬機"></a>2.安裝Linux Ubuntu server虛擬機</h4><p>開啟Virtual Box，首先新增名字為hadoop01的Linux 64位元虛擬機，配置4GB的記憶體、100GB動態配置硬碟空間。設定好後，點右鍵設定值→網路，介面卡要設置兩個，第一個選擇用橋接介面卡，名稱選擇家裡網卡的driver，其功能是為了能連到外面網路，如下圖所示：</p>
<p><img src="http://geekcodeparadise.com/wp-content/uploads/2015/09/25E425BB258B25E9259D25A225E5258D25A11.png" alt="VirtualBox 橋接介面卡"></p>
<p>　　第二個選擇用「僅限主機」介面卡，是用來使本機與虛擬機互相連線，如下圖所示：</p>
<p><img src="http://geekcodeparadise.com/wp-content/uploads/2015/09/25E425BB258B25E9259D25A225E5258D25A12.png" alt="VirtualBox 橋接介面卡 2"></p>
<p>　　接著啟動虛擬機，選擇Ubuntu iso檔安裝。安裝過程重要的地方有5點：</p>
<ul>
<li>(1) 選英文的操作系統，用中文的話會有很高的機率發生路徑&#x2F;軟體不能安裝等問題…..</li>
<li>(2) hostname以本機為例是設定為hadoop01，作為主節點（Master），如下圖所示：</li>
</ul>
<p><img src="http://geekcodeparadise.com/wp-content/uploads/2015/09/25E825A825AD25E525AE259Ahostname.png" alt="hadoop01"></p>
<ul>
<li>(3) 安裝的套件選擇OpenSSH Server、LAMP Server與Samba file Server，OpenSSH是為了能建立安全連線，LAMP Server是包含Apache http server、MySQL與PHP語言，Samba file Server是可以主機間互相修改資料。其他的套件就依個人需求而安裝，如下圖所示，記得要先用空白鍵選擇再按continue</li>
</ul>
<p><img src="http://geekcodeparadise.com/wp-content/uploads/2015/09/25E525AE258925E825A3259DServer25E525A5259725E425BB25B6.png" alt="安裝的套件選擇OpenSSH Server、LAMP Server與Samba file Server"></p>
<ul>
<li>(4) 設定簡單點的Ubuntu登入id&#x2F;pwd，以本機的id&#x2F;pwd都設定為test，方便做測試。</li>
<li>(5) 硬碟的切割選擇用LVM</li>
<li>(6) 選擇安裝 security updates automaticall</li>
</ul>
<p>以上若都正常安裝的話，恭喜您能進入到黑黑的Command Mode登入畫面囉!</p>
<h4 id="3-線上安裝套件"><a href="#3-線上安裝套件" class="headerlink" title="3. 線上安裝套件"></a>3. 線上安裝套件</h4><p>　　接著要透過網路安裝server所需的軟體，首先執行下面指令，更新ubuntu可取得資源的server清單：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br></pre></td></tr></table></figure>

<p>　　以下會有2樣軟體要下載並安裝：</p>
<ul>
<li>(1) Oracle JAVA ：Hadoop執行是在JVM上，環境必須要有安裝JAVA。而目前以Hadoop文件最新測試的穩定JAVA版本是1.7，所以本機安裝1.7版本。安裝要下三行指令：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo add-apt-repository ppa:webupd8team/java</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install oracle-java7-installer</span><br></pre></td></tr></table></figure>

<p>　　其中用指令add-apt-repository ppa:webupd8team&#x2F;java原因 ：Ubuntu的預設資源清單是沒有Oracle的Java，必須透過Ubuntu另外設置的webupd8team網路空間來下載。</p>
<p>　　安裝完後的Java路徑預設是在&#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;java-7-oracle</p>
<p>可以下指令檢查是否Java版本正確</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -version</span><br></pre></td></tr></table></figure>

<ul>
<li>(2) vsftpd：安裝Ubuntu的FTP Server，能夠方便傳檔案到Server，安裝要下此指令：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install vsftpd</span><br></pre></td></tr></table></figure>

<p>　　安裝完成後，修改vsftpd的設定檔</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vi /etc/vsftpd.conf</span><br></pre></td></tr></table></figure>

<p>　　有4項參數要改：</p>
<figure class="highlight apacheconf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#禁止無帳密登入</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">anonymous_enable</span>=NO</span><br><span class="line"></span><br><span class="line"><span class="comment">#接受本地用戶登入</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">local_enable</span>=YES</span><br><span class="line"></span><br><span class="line"><span class="comment">#允許上傳/寫入（預設沒打開，請把前面的#去掉就打開了)</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">write_enable</span>=YES</span><br><span class="line"></span><br><span class="line"><span class="comment">#用戶只能訪問指定目錄</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">chroot_local_user</span>=YES</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>　　設定完後，啟動服務vsftpd</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service vsftpd restart</span><br></pre></td></tr></table></figure>

<h4 id="4-修改網路設定"><a href="#4-修改網路設定" class="headerlink" title="4.修改網路設定"></a>4.修改網路設定</h4><p>　　為了配置每台的虛擬機網路IP，首先設定Virtual Box的網路設定，點選左上的檔案→喜好設定→網路，選取「僅限主機」網路的Virtual Box Host-Only Ethernet Adapter，將網路卡與DHCP伺服器的IP設定如下圖所示（其IP的值是由Virtual Box預設的，若想用別的IP也可行）：</p>
<p><img src="http://geekcodeparadise.com/wp-content/uploads/2015/09/25E725B625B225E825B725AF25E52596259C25E525A525BD25E825A825AD25E525AE259A1.png" alt="虛擬機網路IP"></p>
<p><img src="http://geekcodeparadise.com/wp-content/uploads/2015/09/25E725B625B225E825B725AF25E52596259C25E525A525BD25E825A825AD25E525AE259A2.png" alt="虛擬機網路IP 2"></p>
<p><img src="http://geekcodeparadise.com/wp-content/uploads/2015/09/25E725B625B225E825B725AF25E52596259C25E525A525BD25E825A825AD25E525AE259A3.png" alt="虛擬機網路IP 3"></p>
<p>　　設定完後，在hadoop01下指令更改網路IP設定：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vi /etc/network/interfaces</span><br></pre></td></tr></table></figure>

<p>　　在這檔案內容的下面增加這4行參數設定</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">auto eth1</span><br><span class="line">iface eth1 inet static</span><br><span class="line">address 192.168.56.101</span><br><span class="line">netmask 255.255.255.0</span><br></pre></td></tr></table></figure>

<p>其意思是我們用eth1的內部網路來連線溝通，而IP指定為192.168.56.101。</p>
<p>　　再來更改hosts，直接透過host做網路連線，不必每次都打IP。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vi /etc/hosts</span><br></pre></td></tr></table></figure>

<p>　　在此檔案內容上方的內容增加hadoop01 到 hadoop03的host設定，且要把IPv6的設定註解，否則用Hadoop的相關程式會有問題：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1 localhost</span><br><span class="line">192.168.56.101 hadoop01</span><br><span class="line">192.168.56.102 hadoop02</span><br><span class="line">192.168.56.103 hadoop03</span><br><span class="line"></span><br><span class="line"><span class="comment"># The following lines are desirable for IPv6 capable hosts</span></span><br><span class="line"><span class="comment">#::1 localhost ip6-localhost ip6-loopback</span></span><br><span class="line"><span class="comment">#ff02::1 ip6-allnodes</span></span><br><span class="line"><span class="comment">#ff02::2 ip6-allrouters</span></span><br></pre></td></tr></table></figure>

<p>以上設定完後，將Server重新啟動，再下指令查看是否IP有正確更改</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ip addr show</span><br></pre></td></tr></table></figure>

<p>　　視窗會顯示這樣的訊息：</p>
<p><img src="http://geekcodeparadise.com/wp-content/uploads/2015/09/IPADDRSHOW.png" alt="Hadoop 2.7.1 Cluster 檢查 IP"></p>
<p>　　可看見eth1網路卡有確實設定。  </p>
<p>　　接著設定ssh密鑰的設定，此設定是為了使Hadoop cluster之間連線可免密碼登入。下這兩行指令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 產生dsa的密鑰</span></span><br><span class="line">ssh-keygen -t dsa -P <span class="string">&#x27;&#x27;</span> -f ~/.ssh/id_dsa</span><br><span class="line"><span class="comment"># 將公鑰授權到key</span></span><br><span class="line">$ <span class="built_in">cat</span> ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br></pre></td></tr></table></figure>

<p>　　試著對自己ssh連線：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh hadoop01</span><br></pre></td></tr></table></figure>

<p>會顯示是否連線(yes&#x2F;no) ，輸入yes，會顯示如下圖的訊息：</p>
<p><img src="http://geekcodeparadise.com/wp-content/uploads/2015/09/SSH25E8258725AA25E525B725B1.png" alt="Hadoop 2.7.1 Cluster SSH 連線"></p>
<h4 id="5-下載與安裝Hadoop-2-7-1"><a href="#5-下載與安裝Hadoop-2-7-1" class="headerlink" title="5.下載與安裝Hadoop 2.7.1"></a>5.下載與安裝Hadoop 2.7.1</h4><p>接著是安裝本篇主角－－－Hadoop！使用wget指令從<a target="_blank" rel="noopener" href="http://www.apache.org/dyn/closer.cgi/hadoop/common">Apache官方下載</a>：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo wget http://apache.stu.edu.tw/hadoop/common/hadoop-2.7.1/hadoop-2.7.1.tar.gz</span><br></pre></td></tr></table></figure>

<p>　　下載好後將其解壓縮</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo tar -zxvf hadoop-2.7.1.tar.gz</span><br></pre></td></tr></table></figure>

<p>　　更改Hadoop的設定，首先更改環境路徑的設定：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vi ~/.bashrc</span><br></pre></td></tr></table></figure>

<p>　　在最下方增加這些環境參數：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HADOOP_PREFIX=<span class="string">&quot;/home/test/hadoop-2.7.1&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=<span class="variable">$HADOOP_PREFIX</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_HOME=<span class="variable">$HADOOP_PREFIX</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=<span class="variable">$HADOOP_PREFIX</span>/etc/hadoop</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> HADOOP_HDFS_HOME=<span class="variable">$HADOOP_PREFIX</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> HADOOP_MAPRED_HOME=<span class="variable">$HADOOP_PREFIX</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> HADOOP_YARN_HOME=<span class="variable">$HADOOP_PREFIX</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_LIB_NATIVE_DIR=<span class="variable">$HADOOP_HOME</span>/lib/native</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> HADOOP_OPTS=<span class="string">&quot;-Djava.library.path=<span class="variable">$HADOOP_HOME</span>/lib&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/lib/jvm/java-7-oracle</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin:/home/test/hadoop-2.7.1/bin:/home/test/hadoop-2.7.1/sbin</span><br></pre></td></tr></table></figure>

<p>　　增加後存檔，再使系統重讀.bashrc檔</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure>

<p>　　可以試著打下hadoop指令看看，會出現一些訊息</p>
<p><img src="http://geekcodeparadise.com/wp-content/uploads/2015/09/25E425B8258BHADOOP25E6258C258725E425BB25A4.png" alt="hadoop command"></p>
<p>代表有成功的設定環境變數。</p>
<p>　　將目錄切換到hadoop-2.7.1&#x2F;etc&#x2F;hadoop，須更改6項Hadoop的設定檔：core-site.xml、hdfs-site.xml(主節點mater與從節點slave有不一樣內容)、yarn-site.xml、mapred-site.xml、slaves(節點mater與從節點slave有不一樣內容)、hadoop-env.sh<br>　　hadoop01的設定(namenode master)<br>core-site.xml內容：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop01:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span> <span class="comment">&lt;!-- 將localhost改成hadoop01 host --&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>hdfs-site.xml內容：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/home/test/hdfs/datanode<span class="tag">&lt;/<span class="name">value</span>&gt;</span> <span class="comment">&lt;!-- hadoop hdfs(datanode)設定在此目錄 --&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/home/test/hdfs/namenode<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  <span class="comment">&lt;!-- hadoop hdfs(namenode)設定在此目錄 --&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  <span class="comment">&lt;!-- block 數量　--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>yarn-site.xml內容：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services.mapreduce.shuffle.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span> org.apache.hadoop.mapred.ShuffleHandler<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span> <span class="comment">&lt;!-- 有localhost的都改為hadoop01 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop01:8025<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop01:8030<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop01:8050<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>原始的目錄只有mapred-site.xml.template檔案，需用cp複製一份改成mapred-site.xml：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> mapred-site.xml.template mapred-site.xml</span><br></pre></td></tr></table></figure>

<p>mapred-site.xml內容：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>slaves內容，把localhost那行去掉，改成主節點與從節點的host</p>
<figure class="highlight apacheconf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">hadoop01</span></span><br><span class="line"><span class="attribute">hadoop02</span></span><br><span class="line"><span class="attribute">hadoop03</span></span><br></pre></td></tr></table></figure>

<p>hadoop-env.sh內容，找到[export JAVA_HOME&#x3D;]這一行，將Java的路徑設置：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/lib/jvm/java-7-oracle</span><br></pre></td></tr></table></figure>

<p>以上六項檔案設定完後，在&#x2F;home&#x2F;test底下建立hdfs&#x2F;namenodem和datanode目錄：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#建立目錄</span></span><br><span class="line">sudo <span class="built_in">mkdir</span> -p ~/hdfs/namenode</span><br><span class="line">sudo <span class="built_in">mkdir</span> -p ~/hdfs/datanode</span><br><span class="line"><span class="comment">#更改權限為test使用者，之後啟動hdfs才能正常運作</span></span><br><span class="line">sudo <span class="built_in">chown</span> -R <span class="built_in">test</span>:<span class="built_in">test</span> ~/hdfs/namenode</span><br><span class="line">sudo <span class="built_in">chown</span> -R <span class="built_in">test</span>:<span class="built_in">test</span> ~/hdfs/datanode</span><br><span class="line">sudo <span class="built_in">chown</span> -R <span class="built_in">test</span>:<span class="built_in">test</span> ~</span><br></pre></td></tr></table></figure>

<p>　　以上6項更改完後，將hadoop01關閉，透過Virtual Box複製另外兩個虛擬機hadoop02與hadoop03。 對著hadoop01右鍵→再製，並勾選初始化所有網路卡的MAC位址：</p>
<p><img src="http://geekcodeparadise.com/wp-content/uploads/2015/09/clone.png" alt="複製虛擬機"></p>
<p>複製好這2台虛擬機，分別開啟更改些設定檔(hadoop02&#x2F;hadoop03: datanode slaves)</p>
<ul>
<li>hostname</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo vi /etc/hostname</span><br><span class="line"><span class="comment">#將hadoop01改成對應虛擬機的hadoop02(或hadoop03)</span></span><br></pre></td></tr></table></figure>

<ul>
<li>&#x2F;etc&#x2F;network&#x2F;interfaces</li>
</ul>
<figure class="highlight apacheconf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">auto</span> eth1</span><br><span class="line"><span class="attribute">iface</span> eth1 inet static</span><br><span class="line"><span class="attribute">address</span> <span class="number">192.168.56.102</span> #此IP為hadoop02的，hadoop03的設定改成<span class="number">192.168.56.103</span></span><br><span class="line"><span class="attribute">netmask</span> <span class="number">255.255.255.0</span></span><br></pre></td></tr></table></figure>

<ul>
<li>hadoop-2.7.1&#x2F;etc&#x2F;hadoop&#x2F;slaves內容清空，只增加localhost這一行</li>
</ul>
<figure class="highlight apacheconf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">localhost</span></span><br></pre></td></tr></table></figure>

<ul>
<li>hadoop-2.7.1&#x2F;etc&#x2F;hadoop&#x2F;hdfs-site.xml，內容與hadoop01不同，只有datanode：</li>
</ul>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/home/test/hdfs/datanode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>更改完hdfs-site.xml的內容後，將原本的hdfs&#x2F;namenode刪除，改成hdfs&#x2F;datanode：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo <span class="built_in">rm</span> -Rf ~/hdfs/namenode</span><br><span class="line"><span class="comment">#更改權限為test使用者，之後啟動hdfs才能正常運作</span></span><br><span class="line">sudo <span class="built_in">chown</span> -R <span class="built_in">test</span>:<span class="built_in">test</span> ~/hdfs/datanode</span><br><span class="line">sudo <span class="built_in">chown</span> -R <span class="built_in">test</span>:<span class="built_in">test</span> ~</span><br></pre></td></tr></table></figure>

<p>　　以上更改完後，三台虛擬機都重新啟動，先從hadoop01對hadoop02與hadoop03做ssh連線，確認都可以正常登入：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ssh hadoop02</span><br><span class="line">ssh hadoop03</span><br></pre></td></tr></table></figure>

<p>若能正常ssh登入後，在hadoo01這台下先下這項指令:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#此指令是將namenode初始化</span></span><br><span class="line">hadoop namenode -format</span><br></pre></td></tr></table></figure>

<p>接著再執行start-all.sh指令，這個shell會啟動hdfs與yarn services</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-all.sh</span><br></pre></td></tr></table></figure>

<p>　　會有下圖的啟動資訊，包含log檔的存檔位置：</p>
<p><img src="http://geekcodeparadise.com/wp-content/uploads/2015/09/START-ALL.png" alt="Hadoop 2.7.1 Cluster start-all.sh 啟動"></p>
<p>　　接著下jps指令，查看各台的Hadoop服務是否都正常起動：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jps</span><br></pre></td></tr></table></figure>

<p>以hadoop01(master)的狀態會是如下：</p>
<p><img src="http://geekcodeparadise.com/wp-content/uploads/2015/09/JPS-MASTER.png" alt="Hadoop 2.7.1 Cluster jps 狀態"></p>
<p>　　而hadoop02與hadoop03的狀態會是如下：</p>
<p><img src="http://geekcodeparadise.com/wp-content/uploads/2015/09/JPS-SLAVE.png" alt="Hadoop 2.7.1 Cluster jps 狀態 slave"></p>
<p>若您的三台的jps都跟本篇一樣，代表您成功安裝Hadoop了！</p>
<p><img src="http://geekcodeparadise.com/wp-content/uploads/2015/09/4055767_38d37c85866b5a95bcf9da64b82daf72.gif" alt="恭喜安裝完成"></p>
<p>　　接著在你的瀏覽器輸入網址: 192.168.56.101:50070 ，可以看見datanode的資訊</p>
<p><img src="http://geekcodeparadise.com/wp-content/uploads/2015/09/50070portpage.png" alt="Hadoop 2.7.1 Cluster 網頁"></p>
<p>而輸入網址:192.168.56.101:8088　，可看見job的資訊</p>
<p><img src="http://geekcodeparadise.com/wp-content/uploads/2015/09/8088portpage.png" alt="Hadoop 2.7.1 Cluster Job"></p>
<p>　　若要將Hadoop的service(hdfs與yarn)關閉，在hadoop01下此指令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stop-all.sh</span><br></pre></td></tr></table></figure>

<p>　　會顯示關閉的資訊，之後網頁就連不上囉：</p>
<p><img src="http://geekcodeparadise.com/wp-content/uploads/2015/09/STOP-ALL.png" alt="Hadoop 2.7.1 Cluster 斷線"></p>
<h4 id="6-結論"><a href="#6-結論" class="headerlink" title="6.結論"></a>6.結論</h4><p>　　完成這樣的安裝，才只是成功的一小步……本人在安裝的過程遇到很多問題，使用了不同版本的安裝方式就會出bug，只能說Hadoop變化真的很快！接著會陸續增加怎寫Hadoop的程式、安裝其他的套件等文章，而理論的部份我也正在學習，下面的參考文獻會列出一些翻過的書籍，可以從中了解Hadoop的運作，希望能幫到一起學習Hadoop的同伴，另外本文有錯誤或建議的部分請多指教，會做些修改。</p>
<h4 id="參考文獻"><a href="#參考文獻" class="headerlink" title="參考文獻"></a>參考文獻</h4><ol>
<li><a target="_blank" rel="noopener" href="http://hadoop.apache.org/docs/r2.7.1/">Hadoop 2.7.1官方文件</a></li>
<li><a target="_blank" rel="noopener" href="http://chaalpritam.blogspot.tw/2015/05/hadoop-270-multi-node-cluster-setup-on.html">chaalpritam blog：Hadoop 2.7.0 Multi Node Cluster Setup on Ubuntu 15.04</a>，有影片示範</li>
<li> <a target="_blank" rel="noopener" href="http://woodysclin.blogspot.tw/2014/05/hadoop-240-cluster.html">woodysclinblog：Hadoop 2.4.0 Cluster 多節點安裝紀錄</a> </li>
<li>書籍： <a target="_blank" rel="noopener" href="http://www.books.com.tw/products/0010633714">Hadoop實戰技術手冊(第2版)</a>，這本是中國的Hadoop聖經，有台灣出版社翻譯，內容似乎對中國原版做更正，使用Hadoop 2.3.0作範例</li>
<li>書籍：<a target="_blank" rel="noopener" href="https://www.amazon.com/-/zh_TW/Tom-White/dp/1449311520?crid=H3Z87CYB24CI&keywords=Hadoop:+The+Definitive+Guide&qid=1641613221&sprefix=hadoop+the+definitive+guide,aps,409&sr=8-1&linkCode=ll1&tag=glj89893320b-20&linkId=5dba868200c291617ea24b13999b1b49&language=zh_TW&ref_=as_li_ss_tl">Hadoop: The Definitive Guide</a><a target="_blank" rel="noopener" href="http://shop.oreilly.com/product/0636920033448.do">, 4th Edition</a> ，全球公認的Hadoop聖經，但我認為這本不適合新手…因為這本是講各種核心的運作理論，對於安裝的部分寫得很淺，會讓新手卡關在安裝步驟</li>
<li>書籍：<a target="_blank" rel="noopener" href="https://www.amazon.com/-/zh_TW/Garry-Turkington-ebook/dp/B00BKXQT8S?crid=1UAMK25KJE4SY&keywords=Hadoop+Beginner%27s+Guide&qid=1641613264&sprefix=hadoop+beginner%27s+guide,aps,235&sr=8-2&linkCode=ll1&tag=glj89893320b-20&linkId=762edc055277a4f7967c924a6d1e2373&language=zh_TW&ref_=as_li_ss_tl">Hadoop Beginner’s Guide</a>，這本我認為很適合新手，寫得很好懂，安裝步驟蠻清楚的</li>
</ol>
<h4 id="新增-修改日記"><a href="#新增-修改日記" class="headerlink" title="新增&#x2F;修改日記"></a>新增&#x2F;修改日記</h4><p>2015&#x2F;9&#x2F;20：</p>
<ol>
<li> 將Master hadoop01新增為datanode，更改了hadoop01的hdfs-site.xml、datanode目錄，是為了多個節點運算，之後要用來比較效能用。 </li>
<li>新增stop-all.sh 介紹</li>
</ol>
<p>2015&#x2F;9&#x2F;25：</p>
<ol>
<li>VirtualBox更新成5.0.4版，跟4.X版差不多功能，安裝Ubuntu和Hadoop都正常。</li>
</ol>
<p>2015&#x2F;9&#x2F;26：</p>
<ol>
<li>telnet&#x2F;ssh終端機連線工具新增MobaXterm，有免費版。</li>
</ol>
<p>2015&#x2F;10&#x2F;17：</p>
<ol>
<li>設置成hadoop01 至 hadoop05 五台虛擬機，01為Master，02~05為Slaves。</li>
</ol>
<p>2015&#x2F;11&#x2F;25：</p>
<ol>
<li>更改&#x2F;etc&#x2F;hosts的設定，要將IPv6的設定取消，有遇到使用HBase時zookeeper會connection refused</li>
</ol>
<p>Hadoop 2.7.1 Cluster</p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2014/06/16/programming-contest-learning/" rel="prev" title="程式解題的學習">
      <i class="fa fa-chevron-left"></i> 程式解題的學習
    </a></div>
      <div class="post-nav-item">
    <a href="/2015/09/20/create-hdfs-mapreduce-wordcount/" rel="next" title="Create HDFS MapReduce Wordcount">
      Create HDFS MapReduce Wordcount <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#0-%E5%89%8D%E8%A8%80"><span class="nav-number">1.</span> <span class="nav-text">0.前言</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-%E6%BA%96%E5%82%99%E8%BB%9F%E9%AB%94%E5%B7%A5%E5%85%B7%E8%88%87%E9%85%8D%E5%82%99%E9%9C%80%E6%B1%82"><span class="nav-number">2.</span> <span class="nav-text">1.準備軟體工具與配備需求</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-%E5%AE%89%E8%A3%9DLinux-Ubuntu-server%E8%99%9B%E6%93%AC%E6%A9%9F"><span class="nav-number">3.</span> <span class="nav-text">2.安裝Linux Ubuntu server虛擬機</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-%E7%B7%9A%E4%B8%8A%E5%AE%89%E8%A3%9D%E5%A5%97%E4%BB%B6"><span class="nav-number">4.</span> <span class="nav-text">3. 線上安裝套件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-%E4%BF%AE%E6%94%B9%E7%B6%B2%E8%B7%AF%E8%A8%AD%E5%AE%9A"><span class="nav-number">5.</span> <span class="nav-text">4.修改網路設定</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-%E4%B8%8B%E8%BC%89%E8%88%87%E5%AE%89%E8%A3%9DHadoop-2-7-1"><span class="nav-number">6.</span> <span class="nav-text">5.下載與安裝Hadoop 2.7.1</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-%E7%B5%90%E8%AB%96"><span class="nav-number">7.</span> <span class="nav-text">6.結論</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8F%83%E8%80%83%E6%96%87%E7%8D%BB"><span class="nav-number">8.</span> <span class="nav-text">參考文獻</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%96%B0%E5%A2%9E-%E4%BF%AE%E6%94%B9%E6%97%A5%E8%A8%98"><span class="nav-number">9.</span> <span class="nav-text">新增&#x2F;修改日記</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">LiJyu Gao</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">205</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">48</span>
        <span class="site-state-item-name">categories</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">LiJyu Gao</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

</body>
</html>
